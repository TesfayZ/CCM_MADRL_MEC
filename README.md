# Client-Master Multiagent Deep Reinforcement Learning for Task Offloading in Mobile Edge Computing

This repository contains the implementation code for the paper **"Client-Master Multiagent Deep Reinforcement Learning for Task Offloading in Mobile Edge Computing"**.

üìÑ **Paper**: [ACM Digital Library](https://dl.acm.org/doi/abs/10.1145/3768579)  
üìÑ **Preprint**: [arXiv:2402.11653](https://arxiv.org/abs/2402.11653)

## Repository Structure

The repository is organized into three main folders, each corresponding to the three figures presented in the paper:

```
‚îú‚îÄ‚îÄ s10lre4e3CCM_MADRL_MEC/          # 10 steps per episode experiments
‚îú‚îÄ‚îÄ s100lre4e3CCM_MADRL_MEC/         # 100 steps per episode experiments  
‚îú‚îÄ‚îÄ s100lre4e3CCM_MADRL_MECLabmbda5/ # 100 steps with Œª‚ÇÅ=1, Œª‚ÇÇ=5
‚îî‚îÄ‚îÄ README.md
```

### Folder Naming Convention

- **s10lre4e3CCM_MADRL_MEC**: 10 steps per episode, learning rates of 0.0001 and 0.001 for client and master agents respectively
- **s100lre4e3CCM_MADRL_MEC**: 100 steps per episode experiments
- **s100lre4e3CCM_MADRL_MECLabmbda5**: 100 steps per episode with Œª‚ÇÅ=1, Œª‚ÇÇ=5 for better cost balance

### Directory Contents

Each experiment folder contains:

- **CSV/**: Performance metrics stored for every episode
  - Results available for both training and evaluation environments
  - Only evaluation environment results are discussed in the paper
- **Figures/**: Output plots generated by plotting scripts
- **plotAtTraining.py**: Plots results from training environment
- **Other plotting scripts**: Plot results from evaluation environment

## Usage

### Running the Main Algorithm

Execute the CCM_MADRL_MEC algorithm:

```bash
python run.py <index>
```

Where `<index>` determines the output filename (e.g., `index=0` creates `CCM_MADRL_MEC0.csv`).

**Important**: For multiple experiments, index values must start from 0 and increment sequentially to ensure proper access by plotting scripts.

### Running Benchmark Algorithms

1. Execute benchmarks individually:
   ```bash
   python Benchmarks_run.py <index>
   ```

2. Configure the benchmark mode by replacing `Benchmarks_modes` in line 37 of `Benchmarks_run.py` with one of the available choices (see commented options in the file).

### Generating Plots

1. Adjust the number of runs in line 93 of `plot3.py`
2. Execute the plotting script:
   ```bash
   python plot3.py
   ```

## Important Notes

### Experiment Selection for 100 Steps

For experiments with 100 steps per episode, **use `s100lre4e3CCM_MADRL_MECLabmbda5`** for analysis rather than `s100lre4e3CCM_MADRL_MEC`.

**Rationale**: 
- The experiment with Œª‚ÇÅ=Œª‚ÇÇ=0.5 neglects energy consumption due to its small value compared to latency
- Only latency affects performance in this configuration
- Œª‚ÇÅ=1 and Œª‚ÇÇ=5 provides better balance between latency and energy costs
- Œª‚ÇÅ=1 and Œª‚ÇÇ=1000 is provided in the ACM paper and in the 5th chapter of my [PhD thesis](https://eprints.soton.ac.uk/491435/) 

## Citation

If you use this code in your research, please cite:

```bibtex
@article{10.1145/3768579,
author = {Gebrekidan, Tesfay Zemuy and Stein, Sebastian and Norman, Timothy},
title = {Client-Master Multiagent Deep Reinforcement Learning for Task Offloading in Mobile Edge Computing},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1556-4665},
url = {https://doi.org/10.1145/3768579},
doi = {10.1145/3768579}
}
```

**ArXiv Preprint**:
```bibtex
@misc{gebrekidan2024combinatorial_arxiv,
  title={Combinatorial Client-Master Multiagent Deep Reinforcement Learning for Task Offloading in Mobile Edge Computing}, 
  author={Tesfay Zemuy Gebrekidan and Sebastian Stein and Timothy J. Norman},
  year={2024},
  eprint={2402.11653},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2402.11653}
}
```
